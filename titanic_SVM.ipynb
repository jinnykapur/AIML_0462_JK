{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survival prediction: [nan]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/numpy/core/_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Titanic dataset\n",
    "titanic_df = pd.read_csv('Titanic-Dataset.csv')\n",
    "\n",
    "\n",
    "# Preprocess the data\n",
    "# Fill missing values\n",
    "titanic_df['Age'] = titanic_df['Age'].fillna(titanic_df['Age'].median())\n",
    "titanic_df['Embarked'] = titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0])\n",
    "titanic_df['Fare'] = titanic_df['Fare'].fillna(titanic_df['Fare'].median())\n",
    "\n",
    "# Convert categorical features to numerical\n",
    "titanic_df['Sex'] = titanic_df['Sex'].map({'male': 0, 'female': 1})\n",
    "titanic_df['Embarked'] = titanic_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})\n",
    "\n",
    "# Select features and target variable\n",
    "X = titanic_df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']].values\n",
    "y = titanic_df['Survived'].values\n",
    "\n",
    "# Handle NaN values in mean and std calculations\n",
    "mean_X = np.nanmean(X, axis=0)\n",
    "std_X = np.nanstd(X, axis=0)\n",
    "mean_X = np.nan_to_num(mean_X, nan=0.0)\n",
    "std_X = np.nan_to_num(std_X, nan=1.0)\n",
    "\n",
    "# Normalize features\n",
    "X_norm = (X - mean_X) / (std_X + 1e-8)  # Adding a small epsilon to avoid division by zero\n",
    "\n",
    "# Define SVM class\n",
    "class SVM:\n",
    "    def __init__(self, C=1.0, max_iter=100, tol=1e-3):\n",
    "        self.C = C  # Regularization parameter\n",
    "        self.max_iter = max_iter  # Maximum number of iterations\n",
    "        self.tol = tol  # Tolerance for stopping criteria\n",
    "        self.w = None  # Weight vector\n",
    "        self.b = 0  # Bias term\n",
    "        self.alpha = None  # Lagrange multipliers\n",
    "        self.support_vectors = None  # Support vectors\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        # Initialize Lagrange multipliers\n",
    "        self.alpha = np.zeros(n_samples)\n",
    "\n",
    "        # SMO algorithm for training\n",
    "        for _ in range(self.max_iter):\n",
    "            alpha_prev = np.copy(self.alpha)\n",
    "\n",
    "            for i in range(n_samples):\n",
    "                # Randomly select second Lagrange multiplier\n",
    "                j = np.random.randint(0, n_samples)\n",
    "                while j == i:\n",
    "                    j = np.random.randint(0, n_samples)\n",
    "\n",
    "                # Compute kernel function (linear kernel)\n",
    "                K_ij = np.dot(X[i], X[j])\n",
    "\n",
    "                # Compute SVM decision function for samples i and j\n",
    "                eta = 2.0 * K_ij - K_ij - K_ij\n",
    "\n",
    "                # Update Lagrange multipliers\n",
    "                self.alpha[j] += y[j] * (y[i] * (alpha_prev[i] - self.alpha[i]) - eta)\n",
    "                self.alpha[j] = max(0, min(self.alpha[j], self.C))\n",
    "\n",
    "                self.alpha[i] += y[i] * y[j] * (alpha_prev[j] - self.alpha[j])\n",
    "\n",
    "            # Compute weight vector and bias\n",
    "            self.w = np.dot(self.alpha * y, X)\n",
    "            support_vector_indices = np.where(self.alpha > 1e-5)[0]\n",
    "            self.b = np.mean(y[support_vector_indices] - np.dot(X[support_vector_indices], self.w))\n",
    "\n",
    "            # Check for convergence\n",
    "            diff = np.linalg.norm(self.alpha - alpha_prev)\n",
    "            if diff < self.tol:\n",
    "                break\n",
    "\n",
    "        # Store support vectors\n",
    "        self.support_vectors = X[support_vector_indices]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.sign(np.dot(X, self.w) + self.b)\n",
    "\n",
    "# Instantiate and train the SVM model\n",
    "svm_model = SVM()\n",
    "svm_model.fit(X_norm, y)\n",
    "\n",
    "# Make predictions on a new data point (for demonstration)\n",
    "# Here, we handle missing values in the new data point before making predictions\n",
    "new_data_point = np.array([[1, 0, 30, 1, 0, 50, 1]])  # Example new data point\n",
    "new_data_point_cleaned = np.nan_to_num((new_data_point - mean_X) / (std_X + 1e-8))\n",
    "prediction = svm_model.predict(new_data_point_cleaned)\n",
    "print(\"Survival prediction:\", prediction)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
